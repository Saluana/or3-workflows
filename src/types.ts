import { Message } from '@openrouter/sdk/models';

/**
 * Configuration for a single workflow step.
 */
export interface StepConfig {
  /** The model to use for this step (e.g., 'openai/gpt-3.5-turbo'). */
  model: string;
  /** The prompt/instruction for this step. Supports {{input}} interpolation. */
  prompt: string;
  /** Optional temperature setting (0.0 to 1.0). */
  temperature?: number;
  /** Optional maximum tokens to generate. */
  maxTokens?: number;
  /** Optional list of tools available to this step. */
  tools?: ToolDefinition[];
}

/**
 * Definition of a tool that can be called by the model.
 */
export interface ToolDefinition {
  type: 'function';
  function: {
    name: string;
    description?: string;
    parameters: Record<string, any>;
  };
  /** Optional handler function to execute when this tool is called. */
  handler?: (args: any) => Promise<string> | string;
}

/**
 * Input for running a workflow.
 */
export interface RunInput {
  /** The initial text input/context for the workflow. */
  input: string;
  /** Optional initial message history. */
  messages?: Message[];
  /** Optional attachments (images, files) for the initial step. */
  attachments?: Attachment[];
}

/**
 * Represents an attachment (image, file) to be sent to the model.
 */
export interface Attachment {
  /** URL of the attachment. */
  url?: string;
  /** Base64 encoded content of the attachment. */
  content?: string;
  /** MIME type of the content (required if content is provided). */
  mimeType?: string;
}

/**
 * Result of a workflow execution.
 */
export interface WorkflowResult {
  /** The final text output of the workflow. */
  output: string;
  /** Detailed results for each step executed. */
  steps: StepResult[];
  /** Total duration of the workflow in milliseconds. */
  duration: number;
  /** Total token usage across all steps. */
  usage: TokenUsage;
}

/**
 * Result of a single step execution.
 */
export interface StepResult {
  /** The model used for this step. */
  model: string;
  /** The text output generated by the model. */
  output: string;
  /** Duration of this step in milliseconds. */
  duration: number;
  /** Token usage for this step. */
  usage: TokenUsage;
  /** Optional list of tool calls made during this step. */
  toolCalls?: any[]; // Using any for now as ToolCall type might be complex
  /** Optional error if the step failed. */
  error?: Error;
}

/**
 * Token usage statistics.
 */
export interface TokenUsage {
  prompt_tokens: number;
  completion_tokens: number;
  total_tokens: number;
}

/**
 * Represents a tool call made by the model.
 */
export interface ToolCall {
  id: string;
  type: 'function';
  function: {
    name: string;
    arguments: string;
  };
}

/**
 * Internal representation of a workflow step (sequential or parallel).
 */
export type WorkflowStep =
  | { type: 'step'; config: StepConfig }
  | { type: 'parallel'; configs: StepConfig[] };

/**
 * Definition of a complete workflow.
 */
export interface WorkflowDefinition {
  steps: WorkflowStep[];
}

/**
 * Events emitted during streaming execution.
 */
export type WorkflowEvent =
  | { type: 'step:start'; model: string }
  | { type: 'chunk'; content: string; nodeId: string }
  | { type: 'tool:call'; tool: string; args: any }
  | { type: 'step:done'; output: string; usage: TokenUsage }
  | { type: 'workflow:done'; result: WorkflowResult };

/**
 * Options for running a workflow.
 */
export interface RunOptions {
  /** Callback for handling manual tool calls if no handler is defined. */
  onToolCall?: (name: string, args: any) => Promise<string> | string;
}
